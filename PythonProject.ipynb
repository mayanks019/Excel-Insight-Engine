{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9f87bd",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Organizations often receive large and complex Excel files containing multiple sheets of structured or semi-structured data. Manually exploring these files to understand column types, identify missing values, detect outliers, analyze categorical and date fields, and generate meaningful summaries can be time-consuming and error-prone.\n",
    "\n",
    "The objective is to develop an automated Excel Insights Engine that can:\n",
    "\n",
    "Load Excel files with multiple sheets.\n",
    "Provide essential metadata such as row and column counts, column names, and data types.\n",
    "Detect and quantify missing values.\n",
    "Generate summary statistics for numeric columns.\n",
    "Identify strong correlations between numeric variables.\n",
    "Detect outliers using statistical methods like IQR or Z-score.\n",
    "Analyze categorical columns for frequency distributions and data quality.\n",
    "Identify and summarize patterns in date columns, including day, month, and year distributions.\n",
    "Automatically create visualizations to help users interpret the data.\n",
    "Compile all findings into a structured report in markdown format or plain text.\n",
    "This tool will be useful for data analysts, auditors, business users, and domain experts who need to extract quick insights from Excel data without writing manual code every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5561acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for having access to the functionality of the operating system\n",
    "import pandas as pd # for data manipulation and analysis\n",
    "import numpy as np # for numerical operations\n",
    "import matplotlib.pyplot as plt # for plotting graphs\n",
    "from datetime import datetime # for manipulating dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3e28a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel Insights Engine\n",
      "--------------------\n",
      "Error loading Excel file: [Errno 22] Invalid argument: '--f=c:\\\\Users\\\\mayan\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3e1fe2dafed699c7d2962623b927ad64895e6c2ea.json'\n",
      "Failed to load Excel file. Exiting.\n"
     ]
    }
   ],
   "source": [
    "class ExcelInsights:\n",
    "    \"\"\"\n",
    "    A class to analyze and visualize Excel data and generate insights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path=None):\n",
    "        \"\"\"\n",
    "        Initializes the ExcelInsights class with a file path.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str, optional): The path to the Excel file. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.file_path = file_path # This path will later be used to load the Excel file.\n",
    "        self.data = None # This will store the default DataFrame (usually the first sheet).\n",
    "        self.sheets = {} # Allows multi-sheet Excel files to be handled easily and individually.\n",
    "        self.insights = {} # Central store for all computed insights, useful for generating a final report.\n",
    "\n",
    "    def load_excel(self, file_path=None):\n",
    "        \"\"\"\n",
    "        Load an Excel file into pandas DataFrames.\n",
    "    \n",
    "        Args:\n",
    "            file_path (str, optional): Path to the Excel file to load.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if successful, False otherwise.\n",
    "        \"\"\"\n",
    "        if file_path: # If a file path is provided, use it.\n",
    "            self.file_path = file_path\n",
    "        if not self.file_path: # If no file path is set, return False.\n",
    "            print(\"Error: No file path provided.\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            # Load all sheets from Excel file\n",
    "            excel_file = pd.ExcelFile(self.file_path) # Load the Excel file\n",
    "            sheet_names = excel_file.sheet_names # Get all sheet names into a list\n",
    "            # Print the names of the sheets found in the Excel file.\n",
    "            print(f\"Sheets found: {sheet_names}\")\n",
    "\n",
    "            # Store each sheet as a DataFrame in the sheets dictionary.\n",
    "            for sheet in sheet_names: # ['Sales', 'Employees', 'Customers']\n",
    "                try:\n",
    "                    self.sheets[sheet] = excel_file.parse(sheet_name=sheet, engine=\"openpyxl\")\n",
    "                except TypeError:\n",
    "                    self.sheets[sheet] = pd.read_excel(self.file_path, sheet_name=sheet, engine ='openpyxl')\n",
    "                print(f\"Loaded sheet: {sheet} with {len(self.sheets[sheet])} rows and {len(self.sheets[sheet].columns)} columns.\")\n",
    "\n",
    "            # Set the default data to the first sheet loaded.\n",
    "            if sheet_names: # If there are any sheets, set the first one as the default data.\n",
    "                self.data = self.sheets[sheet_names[0]] # Set the first sheet as the default data.\n",
    "            print(f\"Successfully loaded {len(sheet_names)} from {os.path.basename(self.file_path)}.\")\n",
    "            return True # Return True if the file was loaded successfully.\n",
    "        except Exception as e: # If an error occurs, print it and return False.\n",
    "            print(f\"Error loading Excel file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def get_basic_info(self):\n",
    "        \"\"\"\n",
    "        Get basic information about the loaded data.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary containing basic information about the data.\n",
    "        \"\"\"\n",
    "        if self.data is None: # If no data is loaded, return an empty dictionary.\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return {} # Return an empty dictionary if no data is loaded.\n",
    "        # Get basic information about the DataFrame.\n",
    "        info = {\n",
    "            \"rows\": len(self.data),\n",
    "            \"columns\": len(self.data.columns),\n",
    "            \"column_names\": list(self.data.columns),\n",
    "            \"data_types\": {col: str(dtype) for col, dtype in self.data.dtypes.items()},\n",
    "            \"missing_values\": self.data.isnull().sum().to_dict(),\n",
    "            \"sheets\": list(self.sheets.keys())\n",
    "        }\n",
    "        \n",
    "        self.insights[\"basic_info\"] = info\n",
    "        return info\n",
    "    \n",
    "    \n",
    "    def generate_summary_statistics(self, sheet_name=None):\n",
    "        \"\"\"\n",
    "        Generate summary statistics for numerical columns.\n",
    "        \n",
    "        Args:\n",
    "            sheet_name (str, optional): Name of the sheet to analyze. If None, uses the default data.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing summary statistics.\n",
    "        \"\"\"\n",
    "        if sheet_name and sheet_name in self.sheets:\n",
    "            data = self.sheets[sheet_name]\n",
    "        elif self.data is not None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return {}\n",
    "        \n",
    "        # Get numerical columns\n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        if not numerical_cols:\n",
    "            print(\"No numerical columns found in the data.\")\n",
    "            return {}\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        summary = {\n",
    "            \"numerical_columns\": numerical_cols,\n",
    "            \"statistics\": data[numerical_cols].describe().to_dict()\n",
    "        }\n",
    "        \n",
    "        # Add to insights\n",
    "        if \"summary_statistics\" not in self.insights:\n",
    "            self.insights[\"summary_statistics\"] = {}\n",
    "            \n",
    "        if sheet_name:\n",
    "            self.insights[\"summary_statistics\"][sheet_name] = summary\n",
    "        else:\n",
    "            self.insights[\"summary_statistics\"][\"default\"] = summary\n",
    "            \n",
    "        return summary\n",
    "    \n",
    "    \n",
    "    def find_correlations(self, sheet_name=None, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Find correlations between numerical columns.\n",
    "        \n",
    "        Args:\n",
    "            sheet_name (str, optional): Name of the sheet to analyze. If None, uses the default data.\n",
    "            threshold (float, optional): Correlation threshold to report.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing correlations above the threshold.\n",
    "        \"\"\"\n",
    "        if sheet_name and sheet_name in self.sheets:\n",
    "            data = self.sheets[sheet_name]\n",
    "        elif self.data is not None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return {}\n",
    "        \n",
    "        # Get numerical columns\n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        if len(numerical_cols) < 2:\n",
    "            print(\"Need at least 2 numerical columns to calculate correlations.\")\n",
    "            return {}\n",
    "        \n",
    "        # Calculate correlations\n",
    "        corr_matrix = data[numerical_cols].corr()\n",
    "        \n",
    "        # Find correlations above threshold\n",
    "        high_correlations = {}\n",
    "        for i in range(len(numerical_cols)):\n",
    "            for j in range(i+1, len(numerical_cols)):\n",
    "                col1 = numerical_cols[i]\n",
    "                col2 = numerical_cols[j]\n",
    "                correlation = corr_matrix.loc[col1, col2]\n",
    "                \n",
    "                if abs(correlation) >= threshold:\n",
    "                    high_correlations[f\"{col1} - {col2}\"] = correlation\n",
    "        \n",
    "        # Add to insights\n",
    "        if \"correlations\" not in self.insights:\n",
    "            self.insights[\"correlations\"] = {}\n",
    "            \n",
    "        if sheet_name:\n",
    "            self.insights[\"correlations\"][sheet_name] = high_correlations\n",
    "        else:\n",
    "            self.insights[\"correlations\"][\"default\"] = high_correlations\n",
    "            \n",
    "        return high_correlations\n",
    "    \n",
    "    \n",
    "    \n",
    "    def identify_outliers(self, sheet_name=None, method=\"iqr\", threshold=1.5):\n",
    "        \"\"\"\n",
    "        Identify outliers in numerical columns.\n",
    "        \n",
    "        Args:\n",
    "            sheet_name (str, optional): Name of the sheet to analyze. If None, uses the default data.\n",
    "            method (str, optional): Method to use for outlier detection ('iqr' or 'zscore').\n",
    "            threshold (float, optional): Threshold for outlier detection.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing outliers for each numerical column.\n",
    "        \"\"\"\n",
    "        if sheet_name and sheet_name in self.sheets:\n",
    "            data = self.sheets[sheet_name]\n",
    "        elif self.data is not None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return {}\n",
    "        \n",
    "        # Get numerical columns\n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        if not numerical_cols:\n",
    "            print(\"No numerical columns found in the data.\")\n",
    "            return {}\n",
    "        \n",
    "        outliers = {}\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            col_data = data[col].dropna()\n",
    "            \n",
    "            if method == \"iqr\":\n",
    "                # IQR method\n",
    "                Q1 = col_data.quantile(0.25)\n",
    "                Q3 = col_data.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                lower_bound = Q1 - threshold * IQR\n",
    "                upper_bound = Q3 + threshold * IQR\n",
    "                \n",
    "                col_outliers = col_data[(col_data < lower_bound) | (col_data > upper_bound)]\n",
    "                \n",
    "            elif method == \"zscore\":\n",
    "                # Z-score method\n",
    "                mean = col_data.mean()\n",
    "                std = col_data.std()\n",
    "                \n",
    "                if std == 0:  # Skip columns with zero standard deviation\n",
    "                    continue\n",
    "                    \n",
    "                z_scores = abs((col_data - mean) / std)\n",
    "                col_outliers = col_data[z_scores > threshold]\n",
    "                \n",
    "            else:\n",
    "                print(f\"Unknown method: {method}. Using IQR method instead.\")\n",
    "                Q1 = col_data.quantile(0.25)\n",
    "                Q3 = col_data.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                lower_bound = Q1 - threshold * IQR\n",
    "                upper_bound = Q3 + threshold * IQR\n",
    "                \n",
    "                col_outliers = col_data[(col_data < lower_bound) | (col_data > upper_bound)]\n",
    "            \n",
    "            if not col_outliers.empty:\n",
    "                outliers[col] = {\n",
    "                    \"count\": len(col_outliers),\n",
    "                    \"percentage\": (len(col_outliers) / len(col_data)) * 100,\n",
    "                    \"values\": col_outliers.tolist() if len(col_outliers) <= 10 else col_outliers.tolist()[:10]  # Limit to 10 values\n",
    "                }\n",
    "        \n",
    "        # Add to insights\n",
    "        if \"outliers\" not in self.insights:\n",
    "            self.insights[\"outliers\"] = {}\n",
    "            \n",
    "        if sheet_name:\n",
    "            self.insights[\"outliers\"][sheet_name] = outliers\n",
    "        else:\n",
    "            self.insights[\"outliers\"][\"default\"] = outliers\n",
    "            \n",
    "        return outliers\n",
    "    \n",
    "    \n",
    "    \n",
    "    def analyze_categorical_data(self, sheet_name=None, top_n=5):\n",
    "        \"\"\"\n",
    "        Analyze categorical columns in the data.\n",
    "        \n",
    "        Args:\n",
    "            sheet_name (str, optional): Name of the sheet to analyze. If None, uses the default data.\n",
    "            top_n (int, optional): Number of top categories to include in the analysis.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing analysis of categorical columns.\n",
    "        \"\"\"\n",
    "        if sheet_name and sheet_name in self.sheets:\n",
    "            data = self.sheets[sheet_name]\n",
    "        elif self.data is not None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return {}\n",
    "        \n",
    "        # Get categorical columns (object, string, or category dtype)\n",
    "        categorical_cols = data.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "        \n",
    "        if not categorical_cols:\n",
    "            print(\"No categorical columns found in the data.\")\n",
    "            return {}\n",
    "        \n",
    "        categorical_analysis = {}\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            # Count value frequencies\n",
    "            value_counts = data[col].value_counts()\n",
    "            \n",
    "            # Get top N categories\n",
    "            top_categories = value_counts.head(top_n).to_dict()\n",
    "            \n",
    "            # Calculate percentage of total for each category\n",
    "            total_count = len(data[col].dropna())\n",
    "            top_categories_pct = {k: (v / total_count) * 100 for k, v in top_categories.items()}\n",
    "            \n",
    "            # Count unique values and missing values\n",
    "            unique_count = data[col].nunique()\n",
    "            missing_count = data[col].isnull().sum()\n",
    "            \n",
    "            categorical_analysis[col] = {\n",
    "                \"unique_values\": unique_count,\n",
    "                \"missing_values\": missing_count,\n",
    "                \"missing_percentage\": (missing_count / len(data)) * 100,\n",
    "                \"top_categories\": top_categories,\n",
    "                \"top_categories_pct\": top_categories_pct\n",
    "            }\n",
    "        \n",
    "        # Add to insights\n",
    "        if \"categorical_analysis\" not in self.insights:\n",
    "            self.insights[\"categorical_analysis\"] = {}\n",
    "            \n",
    "        if sheet_name:\n",
    "            self.insights[\"categorical_analysis\"][sheet_name] = categorical_analysis\n",
    "        else:\n",
    "            self.insights[\"categorical_analysis\"][\"default\"] = categorical_analysis\n",
    "            \n",
    "        return categorical_analysis\n",
    "    \n",
    "    \n",
    "    \n",
    "    def analyze_date_columns(self, sheet_name=None):\n",
    "        \"\"\"\n",
    "        Analyze date columns in the data.\n",
    "        \n",
    "        Args:\n",
    "            sheet_name (str, optional): Name of the sheet to analyze. If None, uses the default data.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing analysis of date columns.\n",
    "        \"\"\"\n",
    "        if sheet_name and sheet_name in self.sheets:\n",
    "            data = self.sheets[sheet_name]\n",
    "        elif self.data is not None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return {}\n",
    "        \n",
    "        date_analysis = {}\n",
    "        \n",
    "        # Try to identify date columns\n",
    "        for col in data.columns:\n",
    "            # Check if column is already a datetime type\n",
    "            if pd.api.types.is_datetime64_any_dtype(data[col]):\n",
    "                date_col = data[col]\n",
    "            else:\n",
    "                # Try to convert to datetime\n",
    "                try:\n",
    "                    date_col = pd.to_datetime(data[col], errors='coerce')\n",
    "                    # If more than 70% of values could be converted to dates, consider it a date column\n",
    "                    if date_col.notnull().sum() / len(date_col) < 0.7:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Analyze the date column\n",
    "            date_analysis[col] = {\n",
    "                \"min_date\": date_col.min().strftime('%Y-%m-%d') if not pd.isna(date_col.min()) else None,\n",
    "                \"max_date\": date_col.max().strftime('%Y-%m-%d') if not pd.isna(date_col.max()) else None,\n",
    "                \"range_days\": (date_col.max() - date_col.min()).days if not pd.isna(date_col.min()) and not pd.isna(date_col.max()) else None,\n",
    "                \"missing_values\": date_col.isnull().sum(),\n",
    "                \"missing_percentage\": (date_col.isnull().sum() / len(date_col)) * 100\n",
    "            }\n",
    "            \n",
    "            # Add day of week distribution if there are enough dates\n",
    "            if date_col.notnull().sum() > 10:\n",
    "                day_of_week = date_col.dt.day_name().value_counts().to_dict()\n",
    "                date_analysis[col][\"day_of_week_distribution\"] = day_of_week\n",
    "                \n",
    "                # Add month distribution\n",
    "                month_dist = date_col.dt.month_name().value_counts().to_dict()\n",
    "                date_analysis[col][\"month_distribution\"] = month_dist\n",
    "                \n",
    "                # Add year distribution\n",
    "                year_dist = date_col.dt.year.value_counts().to_dict()\n",
    "                date_analysis[col][\"year_distribution\"] = year_dist\n",
    "        \n",
    "        # Add to insights\n",
    "        if \"date_analysis\" not in self.insights:\n",
    "            self.insights[\"date_analysis\"] = {}\n",
    "            \n",
    "        if sheet_name:\n",
    "            self.insights[\"date_analysis\"][sheet_name] = date_analysis\n",
    "        else:\n",
    "            self.insights[\"date_analysis\"][\"default\"] = date_analysis\n",
    "            \n",
    "        return date_analysis\n",
    "    \n",
    "    def generate_insights_report(self, output_file=None):\n",
    "        \"\"\"\n",
    "        Generate a comprehensive insights report.\n",
    "        \n",
    "        Args:\n",
    "            output_file (str, optional): Path to save the report. If None, returns the report as a string.\n",
    "            \n",
    "        Returns:\n",
    "            str: Report as a string if output_file is None, otherwise None.\n",
    "        \"\"\"\n",
    "        if not self.insights:\n",
    "            print(\"No insights generated. Please analyze the data first.\")\n",
    "            return None\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"# Excel Insights Report\")\n",
    "        report.append(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        # Add file information\n",
    "        if self.file_path:\n",
    "            report.append(f\"## File Information\")\n",
    "            report.append(f\"- File: {os.path.basename(self.file_path)}\")\n",
    "            report.append(f\"- Path: {self.file_path}\")\n",
    "            if \"basic_info\" in self.insights:\n",
    "                info = self.insights[\"basic_info\"]\n",
    "                report.append(f\"- Sheets: {', '.join(info['sheets'])}\")\n",
    "                report.append(f\"- Rows: {info['rows']}\")\n",
    "                report.append(f\"- Columns: {info['columns']}\")\n",
    "                report.append(\"\")\n",
    "        \n",
    "        # Add summary statistics\n",
    "        if \"summary_statistics\" in self.insights:\n",
    "            report.append(\"## Summary Statistics\")\n",
    "            for sheet, stats in self.insights[\"summary_statistics\"].items():\n",
    "                if sheet != \"default\":\n",
    "                    report.append(f\"\\n### Sheet: {sheet}\")\n",
    "                \n",
    "                if not stats.get(\"numerical_columns\"):\n",
    "                    report.append(\"No numerical columns found for analysis.\")\n",
    "                    continue\n",
    "                \n",
    "                report.append(\"The following numerical columns were analyzed:\")\n",
    "                report.append(f\"- {', '.join(stats['numerical_columns'])}\\n\")\n",
    "                \n",
    "                for col, col_stats in stats[\"statistics\"].items():\n",
    "                    report.append(f\"### {col}\")\n",
    "                    report.append(f\"- Count: {col_stats.get('count', 'N/A')}\")\n",
    "                    report.append(f\"- Mean: {col_stats.get('mean', 'N/A'):.2f}\")\n",
    "                    report.append(f\"- Std Dev: {col_stats.get('std', 'N/A'):.2f}\")\n",
    "                    report.append(f\"- Min: {col_stats.get('min', 'N/A'):.2f}\")\n",
    "                    report.append(f\"- 25%: {col_stats.get('25%', 'N/A'):.2f}\")\n",
    "                    report.append(f\"- Median: {col_stats.get('50%', 'N/A'):.2f}\")\n",
    "                    report.append(f\"- 75%: {col_stats.get('75%', 'N/A'):.2f}\")\n",
    "                    report.append(f\"- Max: {col_stats.get('max', 'N/A'):.2f}\")\n",
    "                    report.append(\"\")\n",
    "        \n",
    "        # Add correlations\n",
    "        if \"correlations\" in self.insights:\n",
    "            report.append(\"## Correlations\")\n",
    "            for sheet, corrs in self.insights[\"correlations\"].items():\n",
    "                if sheet != \"default\":\n",
    "                    report.append(f\"\\n### Sheet: {sheet}\")\n",
    "                \n",
    "                if not corrs:\n",
    "                    report.append(\"No significant correlations found.\")\n",
    "                    continue\n",
    "                \n",
    "                report.append(\"The following pairs of columns show significant correlation:\")\n",
    "                for pair, corr in corrs.items():\n",
    "                    report.append(f\"- {pair}: {corr:.2f}\")\n",
    "                report.append(\"\")\n",
    "        \n",
    "        # Add outliers\n",
    "        if \"outliers\" in self.insights:\n",
    "            report.append(\"## Outliers\")\n",
    "            for sheet, outs in self.insights[\"outliers\"].items():\n",
    "                if sheet != \"default\":\n",
    "                    report.append(f\"\\n### Sheet: {sheet}\")\n",
    "                \n",
    "                if not outs:\n",
    "                    report.append(\"No outliers detected.\")\n",
    "                    continue\n",
    "                \n",
    "                for col, out_info in outs.items():\n",
    "                    report.append(f\"### {col}\")\n",
    "                    report.append(f\"- Outlier count: {out_info['count']}\")\n",
    "                    report.append(f\"- Percentage of data: {out_info['percentage']:.2f}%\")\n",
    "                    if out_info['values']:\n",
    "                        report.append(f\"- Sample outliers: {out_info['values']}\")\n",
    "                    report.append(\"\")\n",
    "        \n",
    "        # Add categorical analysis\n",
    "        if \"categorical_analysis\" in self.insights:\n",
    "            report.append(\"## Categorical Data Analysis\")\n",
    "            for sheet, cat_analysis in self.insights[\"categorical_analysis\"].items():\n",
    "                if sheet != \"default\":\n",
    "                    report.append(f\"\\n### Sheet: {sheet}\")\n",
    "                \n",
    "                if not cat_analysis:\n",
    "                    report.append(\"No categorical columns found for analysis.\")\n",
    "                    continue\n",
    "                \n",
    "                for col, col_analysis in cat_analysis.items():\n",
    "                    report.append(f\"### {col}\")\n",
    "                    report.append(f\"- Unique values: {col_analysis['unique_values']}\")\n",
    "                    report.append(f\"- Missing values: {col_analysis['missing_values']} ({col_analysis['missing_percentage']:.2f}%)\")\n",
    "                    \n",
    "                    report.append(\"\\nTop categories:\")\n",
    "                    for category, count in col_analysis['top_categories'].items():\n",
    "                        category_str = str(category) if category is not None else \"NULL\"\n",
    "                        pct = col_analysis['top_categories_pct'].get(category, 0)\n",
    "                        report.append(f\"- {category_str}: {count} ({pct:.2f}%)\")\n",
    "                    report.append(\"\")\n",
    "        \n",
    "        # Add date analysis\n",
    "        if \"date_analysis\" in self.insights:\n",
    "            report.append(\"## Date Analysis\")\n",
    "            for sheet, date_analysis in self.insights[\"date_analysis\"].items():\n",
    "                if sheet != \"default\":\n",
    "                    report.append(f\"\\n### Sheet: {sheet}\")\n",
    "                \n",
    "                if not date_analysis:\n",
    "                    report.append(\"No date columns found for analysis.\")\n",
    "                    continue\n",
    "                \n",
    "                for col, col_analysis in date_analysis.items():\n",
    "                    report.append(f\"### {col}\")\n",
    "                    report.append(f\"- Date range: {col_analysis['min_date']} to {col_analysis['max_date']}\")\n",
    "                    report.append(f\"- Range in days: {col_analysis['range_days']}\")\n",
    "                    report.append(f\"- Missing values: {col_analysis['missing_values']} ({col_analysis['missing_percentage']:.2f}%)\")\n",
    "                    \n",
    "                    if \"day_of_week_distribution\" in col_analysis:\n",
    "                        report.append(\"\\nDay of week distribution:\")\n",
    "                        for day, count in col_analysis['day_of_week_distribution'].items():\n",
    "                            report.append(f\"- {day}: {count}\")\n",
    "                    \n",
    "                    if \"month_distribution\" in col_analysis:\n",
    "                        report.append(\"\\nMonth distribution:\")\n",
    "                        for month, count in col_analysis['month_distribution'].items():\n",
    "                            report.append(f\"- {month}: {count}\")\n",
    "                    \n",
    "                    if \"year_distribution\" in col_analysis:\n",
    "                        report.append(\"\\nYear distribution:\")\n",
    "                        for year, count in col_analysis['year_distribution'].items():\n",
    "                            report.append(f\"- {year}: {count}\")\n",
    "                    report.append(\"\")\n",
    "        \n",
    "        # Compile the report\n",
    "        report_text = \"\\n\".join(report)\n",
    "        \n",
    "        # Save to file if specified\n",
    "        if output_file:\n",
    "            try:\n",
    "                with open(output_file, 'w') as f:\n",
    "                    f.write(report_text)\n",
    "                print(f\"Report saved to {output_file}\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving report: {e}\")\n",
    "                return report_text\n",
    "        \n",
    "        return report_text\n",
    "    \n",
    "    def visualize_data(self, output_dir=None, sheet_name=None):\n",
    "        \"\"\"\n",
    "        Generate visualizations for the data.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str, optional): Directory to save visualizations. If None, displays plots.\n",
    "            sheet_name (str, optional): Name of the sheet to visualize. If None, uses the default data.\n",
    "            \n",
    "        Returns:\n",
    "            list: List of paths to saved visualizations if output_dir is provided, otherwise None.\n",
    "        \"\"\"\n",
    "        if sheet_name and sheet_name in self.sheets:\n",
    "            data = self.sheets[sheet_name]\n",
    "        elif self.data is not None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            print(\"No data loaded. Please load an Excel file first.\")\n",
    "            return []\n",
    "        \n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        saved_files = []\n",
    "        \n",
    "        # Get numerical and categorical columns\n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = data.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "        \n",
    "        # 1. Histograms for numerical columns\n",
    "        for col in numerical_cols[:5]:  # Limit to first 5 columns to avoid too many plots\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(data[col].dropna(), bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            if output_dir:\n",
    "                file_path = os.path.join(output_dir, f\"histogram_{col}.png\")\n",
    "                plt.savefig(file_path)\n",
    "                saved_files.append(file_path)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "        \n",
    "        # 2. Bar charts for categorical columns\n",
    "        for col in categorical_cols[:5]:  # Limit to first 5 columns\n",
    "            # Get top 10 categories\n",
    "            value_counts = data[col].value_counts().head(10)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            bars = plt.bar(value_counts.index.astype(str), value_counts.values, color='lightgreen', edgecolor='black')\n",
    "            plt.title(f'Top 10 Categories in {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add count labels on top of bars\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                        f'{height}', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if output_dir:\n",
    "                file_path = os.path.join(output_dir, f\"barchart_{col}.png\")\n",
    "                plt.savefig(file_path)\n",
    "                saved_files.append(file_path)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "        \n",
    "        # 3. Correlation heatmap for numerical columns\n",
    "        if len(numerical_cols) > 1:\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            corr_matrix = data[numerical_cols].corr()\n",
    "            plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none', aspect='auto')\n",
    "            plt.colorbar(label='Correlation Coefficient')\n",
    "            plt.title('Correlation Heatmap')\n",
    "            \n",
    "            # Add correlation values\n",
    "            for i in range(len(numerical_cols)):\n",
    "                for j in range(len(numerical_cols)):\n",
    "                    plt.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                             ha='center', va='center', \n",
    "                             color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black')\n",
    "            \n",
    "            plt.xticks(range(len(numerical_cols)), numerical_cols, rotation=45, ha='right')\n",
    "            plt.yticks(range(len(numerical_cols)), numerical_cols)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if output_dir:\n",
    "                file_path = os.path.join(output_dir, \"correlation_heatmap.png\")\n",
    "                plt.savefig(file_path)\n",
    "                saved_files.append(file_path)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "        \n",
    "        # 4. Box plots for numerical columns to visualize outliers\n",
    "        if numerical_cols:\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            data[numerical_cols[:10]].boxplot()  # Limit to first 10 columns\n",
    "            plt.title('Box Plots for Numerical Columns')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if output_dir:\n",
    "                file_path = os.path.join(output_dir, \"boxplots.png\")\n",
    "                plt.savefig(file_path)\n",
    "                saved_files.append(file_path)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "        \n",
    "        # 5. Pie charts for categorical columns with few unique values\n",
    "        for col in categorical_cols[:3]:  # Limit to first 3 columns\n",
    "            value_counts = data[col].value_counts()\n",
    "            \n",
    "            # Only create pie chart if there are 10 or fewer unique values\n",
    "            if len(value_counts) <= 10:\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.pie(value_counts.values, labels=value_counts.index.astype(str), \n",
    "                        autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "                plt.title(f'Distribution of {col}')\n",
    "                plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "                \n",
    "                if output_dir:\n",
    "                    file_path = os.path.join(output_dir, f\"piechart_{col}.png\")\n",
    "                    plt.savefig(file_path)\n",
    "                    saved_files.append(file_path)\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "        \n",
    "        return saved_files\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    def main():\n",
    "        \"\"\"\n",
    "        Main function to demonstrate the Excel Insights Engine.\n",
    "        \"\"\"\n",
    "        print(\"Excel Insights Engine\")\n",
    "        print(\"--------------------\")\n",
    "        \n",
    "        # Check if a file path was provided as an argument\n",
    "        import sys\n",
    "        if len(sys.argv) > 1:\n",
    "            file_path = sys.argv[1]\n",
    "        else:\n",
    "            # Use a sample file for demonstration\n",
    "            file_path = \"samples/sample_data.xlsx\"\n",
    "            print(f\"No file specified. Using sample file: {file_path}\")\n",
    "        \n",
    "        # Create an instance of ExcelInsights\n",
    "        insights = ExcelInsights(file_path)\n",
    "        \n",
    "        # Try to load the Excel file\n",
    "        if not insights.load_excel():\n",
    "            print(\"Failed to load Excel file. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Get basic information\n",
    "        print(\"\\nGetting basic information...\")\n",
    "        info = insights.get_basic_info()\n",
    "        print(f\"Rows: {info.get('rows', 'N/A')}\")\n",
    "        print(f\"Columns: {info.get('columns', 'N/A')}\")\n",
    "        print(f\"Column names: {', '.join(info.get('column_names', []))}\")\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        print(\"\\nGenerating summary statistics...\")\n",
    "        insights.generate_summary_statistics()\n",
    "        \n",
    "        # Find correlations\n",
    "        print(\"\\nFinding correlations...\")\n",
    "        correlations = insights.find_correlations(threshold=0.7)\n",
    "        if correlations:\n",
    "            print(\"Found correlations:\")\n",
    "            for pair, corr in correlations.items():\n",
    "                print(f\"  {pair}: {corr:.2f}\")\n",
    "        else:\n",
    "            print(\"No significant correlations found.\")\n",
    "        \n",
    "        # Identify outliers\n",
    "        print(\"\\nIdentifying outliers...\")\n",
    "        outliers = insights.identify_outliers()\n",
    "        if outliers:\n",
    "            print(\"Found outliers in the following columns:\")\n",
    "            for col, out_info in outliers.items():\n",
    "                print(f\"  {col}: {out_info['count']} outliers ({out_info['percentage']:.2f}%)\")\n",
    "        else:\n",
    "            print(\"No outliers found.\")\n",
    "        \n",
    "        # Analyze categorical data\n",
    "        print(\"\\nAnalyzing categorical data...\")\n",
    "        insights.analyze_categorical_data()\n",
    "        \n",
    "        # Analyze date columns\n",
    "        print(\"\\nAnalyzing date columns...\")\n",
    "        insights.analyze_date_columns()\n",
    "        \n",
    "        # Generate visualizations\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        vis_dir = \"visualizations\"\n",
    "        saved_files = insights.visualize_data(output_dir=vis_dir)\n",
    "        if saved_files:\n",
    "            print(f\"Saved {len(saved_files)} visualizations to {vis_dir} directory.\")\n",
    "        \n",
    "        # Generate insights report\n",
    "        print(\"\\nGenerating insights report...\")\n",
    "        report_file = \"insights_report.md\"\n",
    "        insights.generate_insights_report(output_file=report_file)\n",
    "        print(f\"Report saved to {report_file}\")\n",
    "        \n",
    "        print(\"\\nAnalysis complete!\")\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d210aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets found: ['Sales', 'Employees', 'Customers']\n",
      "Loaded sheet: Sales with 366 rows and 16 columns.\n",
      "Loaded sheet: Employees with 100 rows and 14 columns.\n",
      "Loaded sheet: Customers with 200 rows and 15 columns.\n",
      "Successfully loaded 3 from sample_data.xlsx.\n",
      "\n",
      "\n",
      "Basic Information:\n",
      "rows: 366\n",
      "columns: 16\n",
      "column_names: ['Date', 'Product', 'Category', 'Region', 'Units_Sold', 'Unit_Price', 'Shipping_Cost', 'Discount_Pct', 'Customer_Rating', 'Returns', 'Total_Sales', 'Month', 'Day_of_Week', 'Is_Weekend', 'Profit', 'Profit_Margin']\n",
      "data_types: {'Date': 'datetime64[ns]', 'Product': 'object', 'Category': 'object', 'Region': 'object', 'Units_Sold': 'int64', 'Unit_Price': 'float64', 'Shipping_Cost': 'float64', 'Discount_Pct': 'float64', 'Customer_Rating': 'float64', 'Returns': 'int64', 'Total_Sales': 'float64', 'Month': 'object', 'Day_of_Week': 'object', 'Is_Weekend': 'bool', 'Profit': 'float64', 'Profit_Margin': 'float64'}\n",
      "missing_values: {'Date': 0, 'Product': 0, 'Category': 0, 'Region': 0, 'Units_Sold': 0, 'Unit_Price': 0, 'Shipping_Cost': 15, 'Discount_Pct': 17, 'Customer_Rating': 23, 'Returns': 0, 'Total_Sales': 0, 'Month': 0, 'Day_of_Week': 0, 'Is_Weekend': 0, 'Profit': 15, 'Profit_Margin': 15}\n",
      "sheets: ['Sales', 'Employees', 'Customers']\n",
      "\n",
      "\n",
      "Summary Statistics\n",
      "numerical_columns: ['Units_Sold', 'Unit_Price', 'Shipping_Cost', 'Discount_Pct', 'Customer_Rating', 'Returns', 'Total_Sales', 'Profit', 'Profit_Margin']\n",
      "statistics: {'Units_Sold': {'count': 366.0, 'mean': 27.47814207650273, 'std': 20.22756326013523, 'min': 1.0, '25%': 14.0, '50%': 27.0, '75%': 38.0, 'max': 174.0}, 'Unit_Price': {'count': 366.0, 'mean': 522.6271584699452, 'std': 328.8882647054234, 'min': 10.24, '25%': 240.26999999999998, '50%': 527.25, '75%': 762.23, 'max': 1996.29}, 'Shipping_Cost': {'count': 351.0, 'mean': 27.370028490028492, 'std': 12.22020005678129, 'min': 5.06, '25%': 16.745, '50%': 28.13, '75%': 37.245000000000005, 'max': 49.8}, 'Discount_Pct': {'count': 349.0, 'mean': 10.673352435530086, 'std': 7.1652823130308185, 'min': 0.0, '25%': 5.0, '50%': 10.0, '75%': 15.0, 'max': 20.0}, 'Customer_Rating': {'count': 343.0, 'mean': 2.988338192419825, 'std': 1.3891321628963942, 'min': 1.0, '25%': 2.0, '50%': 3.0, '75%': 4.0, 'max': 5.0}, 'Returns': {'count': 366.0, 'mean': 0.05737704918032787, 'std': 0.23288001477163284, 'min': 0.0, '25%': 0.0, '50%': 0.0, '75%': 0.0, 'max': 1.0}, 'Total_Sales': {'count': 366.0, 'mean': 11701.770355191258, 'std': 10136.923608265966, 'min': 50.83, '25%': 3326.075, '50%': 9243.625, '75%': 17944.0275, 'max': 42446.25}, 'Profit': {'count': 351.0, 'mean': 11640.239458689459, 'std': 10144.278968925968, 'min': 15.82, '25%': 3332.13, '50%': 9108.4, '75%': 17907.175, 'max': 42416.84}, 'Profit_Margin': {'count': 351.0, 'mean': 98.4385754985755, 'std': 5.7065752771315825, 'min': 31.12, '25%': 99.065, '50%': 99.74, '75%': 99.86, 'max': 99.98}}\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the class ExcelInsights\n",
    "file_path = \"samples/sample_data.xlsx\"  # Path to the Excel file\n",
    "excel_insights = ExcelInsights(file_path)\n",
    "# Call load_excel() method to load the Excel file\n",
    "excel_insights.load_excel()\n",
    "print(\"\\n\\nBasic Information:\")\n",
    "# Call get_basic_info() method to get basic information about the loaded data\n",
    "basic_info = excel_insights.get_basic_info()\n",
    "# Print the basic information\n",
    "for key, value in basic_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "print (\"\\n\\nSummary Statistics\")   \n",
    "summary_statistics =excel_insights.generate_summary_statistics()\n",
    "for key, value in summary_statistics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2a1947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel_insights.file_path (repr): 'samples/sample_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"excel_insights.file_path (repr):\", repr(excel_insights.file_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1595396",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: openpyxl\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'e:\\\\project python\\\\your_script.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425dc720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b098f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4b877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967618f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3414f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad95a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39164eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912ee55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb851d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0191dc58",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
